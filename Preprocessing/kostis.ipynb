{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05fd5125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "481d5e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Successfully loaded /Users/kostis/02582-Computational-Data-Analysis-Case-2/data/HR_data.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Shape of the dataframe: (312, 68)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path ='/Users/kostis/02582-Computational-Data-Analysis-Case-2/data/HR_data.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "display(f\"Successfully loaded {file_path}\")\n",
    "display(f\"Shape of the dataframe: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1044a024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First 5 rows of the data:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>HR_TD_Mean</th>\n",
       "      <th>HR_TD_Median</th>\n",
       "      <th>HR_TD_std</th>\n",
       "      <th>HR_TD_Min</th>\n",
       "      <th>HR_TD_Max</th>\n",
       "      <th>HR_TD_AUC</th>\n",
       "      <th>HR_TD_Kurtosis</th>\n",
       "      <th>HR_TD_Skew</th>\n",
       "      <th>HR_TD_Slope_min</th>\n",
       "      <th>...</th>\n",
       "      <th>upset</th>\n",
       "      <th>hostile</th>\n",
       "      <th>alert</th>\n",
       "      <th>ashamed</th>\n",
       "      <th>inspired</th>\n",
       "      <th>nervous</th>\n",
       "      <th>attentive</th>\n",
       "      <th>afraid</th>\n",
       "      <th>active</th>\n",
       "      <th>determined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>78.663878</td>\n",
       "      <td>76.70</td>\n",
       "      <td>7.480043</td>\n",
       "      <td>67.25</td>\n",
       "      <td>92.48</td>\n",
       "      <td>23048.450</td>\n",
       "      <td>-1.091448</td>\n",
       "      <td>0.369955</td>\n",
       "      <td>-0.7300</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>76.540732</td>\n",
       "      <td>76.61</td>\n",
       "      <td>2.584756</td>\n",
       "      <td>69.82</td>\n",
       "      <td>82.33</td>\n",
       "      <td>23959.920</td>\n",
       "      <td>-0.245338</td>\n",
       "      <td>0.338732</td>\n",
       "      <td>-0.3600</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>78.173563</td>\n",
       "      <td>77.92</td>\n",
       "      <td>2.681255</td>\n",
       "      <td>72.22</td>\n",
       "      <td>82.80</td>\n",
       "      <td>20324.605</td>\n",
       "      <td>-0.615922</td>\n",
       "      <td>-0.233047</td>\n",
       "      <td>-0.6300</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>83.073688</td>\n",
       "      <td>83.88</td>\n",
       "      <td>7.363598</td>\n",
       "      <td>69.42</td>\n",
       "      <td>96.12</td>\n",
       "      <td>24924.300</td>\n",
       "      <td>-0.866610</td>\n",
       "      <td>-0.046021</td>\n",
       "      <td>-0.4650</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>72.281250</td>\n",
       "      <td>72.91</td>\n",
       "      <td>3.193762</td>\n",
       "      <td>64.95</td>\n",
       "      <td>79.98</td>\n",
       "      <td>23052.100</td>\n",
       "      <td>0.200401</td>\n",
       "      <td>-0.560948</td>\n",
       "      <td>-0.3725</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  HR_TD_Mean  HR_TD_Median  HR_TD_std  HR_TD_Min  HR_TD_Max  \\\n",
       "0           0   78.663878         76.70   7.480043      67.25      92.48   \n",
       "1           1   76.540732         76.61   2.584756      69.82      82.33   \n",
       "2           2   78.173563         77.92   2.681255      72.22      82.80   \n",
       "3           3   83.073688         83.88   7.363598      69.42      96.12   \n",
       "4           4   72.281250         72.91   3.193762      64.95      79.98   \n",
       "\n",
       "   HR_TD_AUC  HR_TD_Kurtosis  HR_TD_Skew  HR_TD_Slope_min  ...  upset  \\\n",
       "0  23048.450       -1.091448    0.369955          -0.7300  ...    1.0   \n",
       "1  23959.920       -0.245338    0.338732          -0.3600  ...    2.0   \n",
       "2  20324.605       -0.615922   -0.233047          -0.6300  ...    1.0   \n",
       "3  24924.300       -0.866610   -0.046021          -0.4650  ...    1.0   \n",
       "4  23052.100        0.200401   -0.560948          -0.3725  ...    3.0   \n",
       "\n",
       "   hostile  alert  ashamed  inspired  nervous  attentive  afraid  active  \\\n",
       "0      1.0    2.0      1.0       2.0      2.0        3.0     1.0     2.0   \n",
       "1      1.0    3.0      2.0       2.0      2.0        3.0     1.0     3.0   \n",
       "2      1.0    2.0      1.0       3.0      2.0        3.0     2.0     3.0   \n",
       "3      1.0    2.0      1.0       3.0      2.0        3.0     2.0     3.0   \n",
       "4      1.0    3.0      2.0       3.0      3.0        4.0     2.0     4.0   \n",
       "\n",
       "   determined  \n",
       "0         2.0  \n",
       "1         3.0  \n",
       "2         3.0  \n",
       "3         3.0  \n",
       "4         4.0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display first 5 rows\n",
    "display(\"First 5 rows of the data:\")\n",
    "display(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d216e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\nDataframe Info:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 312 entries, 0 to 311\n",
      "Data columns (total 68 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Unnamed: 0           312 non-null    int64  \n",
      " 1   HR_TD_Mean           312 non-null    float64\n",
      " 2   HR_TD_Median         312 non-null    float64\n",
      " 3   HR_TD_std            312 non-null    float64\n",
      " 4   HR_TD_Min            312 non-null    float64\n",
      " 5   HR_TD_Max            312 non-null    float64\n",
      " 6   HR_TD_AUC            312 non-null    float64\n",
      " 7   HR_TD_Kurtosis       312 non-null    float64\n",
      " 8   HR_TD_Skew           312 non-null    float64\n",
      " 9   HR_TD_Slope_min      312 non-null    float64\n",
      " 10  HR_TD_Slope_max      312 non-null    float64\n",
      " 11  HR_TD_Slope_mean     312 non-null    float64\n",
      " 12  HR_TD_Slope          312 non-null    float64\n",
      " 13  TEMP_TD_Mean         312 non-null    float64\n",
      " 14  TEMP_TD_Median       312 non-null    float64\n",
      " 15  TEMP_TD_std          312 non-null    float64\n",
      " 16  TEMP_TD_Min          312 non-null    float64\n",
      " 17  TEMP_TD_Max          312 non-null    float64\n",
      " 18  TEMP_TD_AUC          312 non-null    float64\n",
      " 19  TEMP_TD_Kurtosis     312 non-null    float64\n",
      " 20  TEMP_TD_Skew         312 non-null    float64\n",
      " 21  TEMP_TD_Slope_min    312 non-null    float64\n",
      " 22  TEMP_TD_Slope_max    312 non-null    float64\n",
      " 23  TEMP_TD_Slope_mean   312 non-null    float64\n",
      " 24  TEMP_TD_Slope        312 non-null    float64\n",
      " 25  EDA_TD_P_Mean        312 non-null    float64\n",
      " 26  EDA_TD_P_Median      312 non-null    float64\n",
      " 27  EDA_TD_P_std         312 non-null    float64\n",
      " 28  EDA_TD_P_Min         312 non-null    float64\n",
      " 29  EDA_TD_P_Max         312 non-null    float64\n",
      " 30  EDA_TD_P_AUC         312 non-null    float64\n",
      " 31  EDA_TD_P_Kurtosis    312 non-null    float64\n",
      " 32  EDA_TD_P_Skew        312 non-null    float64\n",
      " 33  EDA_TD_P_Slope_min   312 non-null    float64\n",
      " 34  EDA_TD_P_Slope_max   312 non-null    float64\n",
      " 35  EDA_TD_P_Slope_mean  312 non-null    float64\n",
      " 36  EDA_TD_P_Slope       312 non-null    float64\n",
      " 37  EDA_TD_T_Mean        312 non-null    float64\n",
      " 38  EDA_TD_T_Median      312 non-null    float64\n",
      " 39  EDA_TD_T_std         312 non-null    float64\n",
      " 40  EDA_TD_T_Min         312 non-null    float64\n",
      " 41  EDA_TD_T_Max         312 non-null    float64\n",
      " 42  EDA_TD_T_AUC         312 non-null    float64\n",
      " 43  EDA_TD_T_Kurtosis    312 non-null    float64\n",
      " 44  EDA_TD_T_Skew        312 non-null    float64\n",
      " 45  EDA_TD_T_Slope_min   312 non-null    float64\n",
      " 46  EDA_TD_T_Slope_max   312 non-null    float64\n",
      " 47  EDA_TD_T_Slope_mean  312 non-null    float64\n",
      " 48  EDA_TD_T_Slope       312 non-null    float64\n",
      " 49  EDA_TD_P_Peaks       312 non-null    int64  \n",
      " 50  EDA_TD_P_RT          311 non-null    float64\n",
      " 51  EDA_TD_P_ReT         311 non-null    float64\n",
      " 52  Round                312 non-null    object \n",
      " 53  Phase                312 non-null    object \n",
      " 54  Individual           312 non-null    int64  \n",
      " 55  Puzzler              312 non-null    int64  \n",
      " 56  Frustrated           312 non-null    float64\n",
      " 57  Cohort               312 non-null    object \n",
      " 58  upset                312 non-null    float64\n",
      " 59  hostile              312 non-null    float64\n",
      " 60  alert                312 non-null    float64\n",
      " 61  ashamed              312 non-null    float64\n",
      " 62  inspired             310 non-null    float64\n",
      " 63  nervous              312 non-null    float64\n",
      " 64  attentive            311 non-null    float64\n",
      " 65  afraid               311 non-null    float64\n",
      " 66  active               311 non-null    float64\n",
      " 67  determined           310 non-null    float64\n",
      "dtypes: float64(61), int64(4), object(3)\n",
      "memory usage: 165.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display DataFrame Info\n",
    "display(\"\\\\nDataframe Info:\")\n",
    "# Increase max_rows display temporarily if needed to see all columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "df.info()\n",
    "pd.reset_option('display.max_rows') # Reset display option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237ad2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\nSummary Statistics (Numerical Columns):'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>HR_TD_Mean</th>\n",
       "      <th>HR_TD_Median</th>\n",
       "      <th>HR_TD_std</th>\n",
       "      <th>HR_TD_Min</th>\n",
       "      <th>HR_TD_Max</th>\n",
       "      <th>HR_TD_AUC</th>\n",
       "      <th>HR_TD_Kurtosis</th>\n",
       "      <th>HR_TD_Skew</th>\n",
       "      <th>HR_TD_Slope_min</th>\n",
       "      <th>...</th>\n",
       "      <th>upset</th>\n",
       "      <th>hostile</th>\n",
       "      <th>alert</th>\n",
       "      <th>ashamed</th>\n",
       "      <th>inspired</th>\n",
       "      <th>nervous</th>\n",
       "      <th>attentive</th>\n",
       "      <th>afraid</th>\n",
       "      <th>active</th>\n",
       "      <th>determined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>311.000000</td>\n",
       "      <td>311.000000</td>\n",
       "      <td>311.000000</td>\n",
       "      <td>310.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>155.500000</td>\n",
       "      <td>78.549974</td>\n",
       "      <td>77.452869</td>\n",
       "      <td>6.545680</td>\n",
       "      <td>68.778365</td>\n",
       "      <td>92.451122</td>\n",
       "      <td>24307.558590</td>\n",
       "      <td>-0.054661</td>\n",
       "      <td>0.375978</td>\n",
       "      <td>-0.567952</td>\n",
       "      <td>...</td>\n",
       "      <td>1.346154</td>\n",
       "      <td>1.057692</td>\n",
       "      <td>2.192308</td>\n",
       "      <td>1.221154</td>\n",
       "      <td>2.183871</td>\n",
       "      <td>1.381410</td>\n",
       "      <td>2.784566</td>\n",
       "      <td>1.051447</td>\n",
       "      <td>2.553055</td>\n",
       "      <td>2.912903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>90.210864</td>\n",
       "      <td>11.382695</td>\n",
       "      <td>12.093798</td>\n",
       "      <td>4.998885</td>\n",
       "      <td>9.341107</td>\n",
       "      <td>17.759683</td>\n",
       "      <td>4035.278119</td>\n",
       "      <td>1.671170</td>\n",
       "      <td>0.823875</td>\n",
       "      <td>0.391239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617576</td>\n",
       "      <td>0.271719</td>\n",
       "      <td>1.037034</td>\n",
       "      <td>0.549014</td>\n",
       "      <td>1.027958</td>\n",
       "      <td>0.577199</td>\n",
       "      <td>1.113793</td>\n",
       "      <td>0.273430</td>\n",
       "      <td>1.173463</td>\n",
       "      <td>1.104050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.606118</td>\n",
       "      <td>54.130000</td>\n",
       "      <td>0.834390</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>67.200000</td>\n",
       "      <td>14853.260000</td>\n",
       "      <td>-1.644825</td>\n",
       "      <td>-2.230501</td>\n",
       "      <td>-3.366000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>77.750000</td>\n",
       "      <td>71.061238</td>\n",
       "      <td>69.971250</td>\n",
       "      <td>3.160342</td>\n",
       "      <td>62.192500</td>\n",
       "      <td>80.207500</td>\n",
       "      <td>21549.048750</td>\n",
       "      <td>-0.984473</td>\n",
       "      <td>-0.151022</td>\n",
       "      <td>-0.665208</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>155.500000</td>\n",
       "      <td>76.784284</td>\n",
       "      <td>75.600000</td>\n",
       "      <td>4.919862</td>\n",
       "      <td>67.565000</td>\n",
       "      <td>87.830000</td>\n",
       "      <td>23650.430000</td>\n",
       "      <td>-0.456978</td>\n",
       "      <td>0.361195</td>\n",
       "      <td>-0.457500</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>233.250000</td>\n",
       "      <td>83.566296</td>\n",
       "      <td>83.108750</td>\n",
       "      <td>8.006694</td>\n",
       "      <td>73.805000</td>\n",
       "      <td>99.452500</td>\n",
       "      <td>26543.927500</td>\n",
       "      <td>0.216412</td>\n",
       "      <td>0.988498</td>\n",
       "      <td>-0.317500</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>311.000000</td>\n",
       "      <td>151.942434</td>\n",
       "      <td>167.950000</td>\n",
       "      <td>32.155396</td>\n",
       "      <td>111.070000</td>\n",
       "      <td>172.470000</td>\n",
       "      <td>46069.990000</td>\n",
       "      <td>12.510032</td>\n",
       "      <td>3.225347</td>\n",
       "      <td>-0.112500</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  HR_TD_Mean  HR_TD_Median   HR_TD_std   HR_TD_Min  \\\n",
       "count  312.000000  312.000000    312.000000  312.000000  312.000000   \n",
       "mean   155.500000   78.549974     77.452869    6.545680   68.778365   \n",
       "std     90.210864   11.382695     12.093798    4.998885    9.341107   \n",
       "min      0.000000   57.606118     54.130000    0.834390   49.000000   \n",
       "25%     77.750000   71.061238     69.971250    3.160342   62.192500   \n",
       "50%    155.500000   76.784284     75.600000    4.919862   67.565000   \n",
       "75%    233.250000   83.566296     83.108750    8.006694   73.805000   \n",
       "max    311.000000  151.942434    167.950000   32.155396  111.070000   \n",
       "\n",
       "        HR_TD_Max     HR_TD_AUC  HR_TD_Kurtosis  HR_TD_Skew  HR_TD_Slope_min  \\\n",
       "count  312.000000    312.000000      312.000000  312.000000       312.000000   \n",
       "mean    92.451122  24307.558590       -0.054661    0.375978        -0.567952   \n",
       "std     17.759683   4035.278119        1.671170    0.823875         0.391239   \n",
       "min     67.200000  14853.260000       -1.644825   -2.230501        -3.366000   \n",
       "25%     80.207500  21549.048750       -0.984473   -0.151022        -0.665208   \n",
       "50%     87.830000  23650.430000       -0.456978    0.361195        -0.457500   \n",
       "75%     99.452500  26543.927500        0.216412    0.988498        -0.317500   \n",
       "max    172.470000  46069.990000       12.510032    3.225347        -0.112500   \n",
       "\n",
       "       ...       upset     hostile       alert     ashamed    inspired  \\\n",
       "count  ...  312.000000  312.000000  312.000000  312.000000  310.000000   \n",
       "mean   ...    1.346154    1.057692    2.192308    1.221154    2.183871   \n",
       "std    ...    0.617576    0.271719    1.037034    0.549014    1.027958   \n",
       "min    ...    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%    ...    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "50%    ...    1.000000    1.000000    2.000000    1.000000    2.000000   \n",
       "75%    ...    2.000000    1.000000    3.000000    1.000000    3.000000   \n",
       "max    ...    4.000000    3.000000    5.000000    4.000000    5.000000   \n",
       "\n",
       "          nervous   attentive      afraid      active  determined  \n",
       "count  312.000000  311.000000  311.000000  311.000000  310.000000  \n",
       "mean     1.381410    2.784566    1.051447    2.553055    2.912903  \n",
       "std      0.577199    1.113793    0.273430    1.173463    1.104050  \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000  \n",
       "25%      1.000000    2.000000    1.000000    2.000000    2.000000  \n",
       "50%      1.000000    3.000000    1.000000    2.000000    3.000000  \n",
       "75%      2.000000    4.000000    1.000000    3.000000    4.000000  \n",
       "max      3.000000    5.000000    4.000000    5.000000    5.000000  \n",
       "\n",
       "[8 rows x 65 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display Summary Statistics (Numerical)\n",
    "display(\"\\\\nSummary Statistics (Numerical Columns):\")\n",
    "display(df.describe(include=np.number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320bf85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\nSummary Statistics (Object Columns):'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Phase</th>\n",
       "      <th>Cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>312</td>\n",
       "      <td>312</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>round_3</td>\n",
       "      <td>phase3</td>\n",
       "      <td>D1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>78</td>\n",
       "      <td>104</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Round   Phase Cohort\n",
       "count       312     312    312\n",
       "unique        4       3      6\n",
       "top     round_3  phase3   D1_1\n",
       "freq         78     104     96"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display Summary Statistics (Categorical/Object)\n",
    "display(\"\\\\nSummary Statistics (Object Columns):\")\n",
    "display(df.describe(include='object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0912f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\nMissing Value Counts per Column:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EDA_TD_P_RT     1\n",
       "EDA_TD_P_ReT    1\n",
       "inspired        2\n",
       "attentive       1\n",
       "afraid          1\n",
       "active          1\n",
       "determined      2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display Missing Value Counts\n",
    "display(\"\\\\nMissing Value Counts per Column:\")\n",
    "missing_values = df.isnull().sum()\n",
    "display(missing_values[missing_values > 0]) # Only show columns with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a992850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\nMinimum values in numerical columns (checking for non-negativity):'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HR_TD_Kurtosis           -1.644825\n",
       "HR_TD_Skew               -2.230501\n",
       "HR_TD_Slope_min          -3.366000\n",
       "HR_TD_Slope_mean         -0.230410\n",
       "HR_TD_Slope              -0.229441\n",
       "TEMP_TD_Kurtosis         -1.672291\n",
       "TEMP_TD_Skew             -2.729638\n",
       "TEMP_TD_Slope_min        -0.004630\n",
       "TEMP_TD_Slope_max        -0.000360\n",
       "TEMP_TD_Slope_mean       -0.000953\n",
       "TEMP_TD_Slope            -0.000889\n",
       "EDA_TD_P_Min             -1.768365\n",
       "EDA_TD_P_Kurtosis        -0.862496\n",
       "EDA_TD_P_Skew            -0.518895\n",
       "EDA_TD_P_Slope_min       -0.351512\n",
       "EDA_TD_P_Slope_mean      -0.001271\n",
       "EDA_TD_P_Slope           -0.002187\n",
       "EDA_TD_T_Mean            -0.898882\n",
       "EDA_TD_T_Median          -0.854923\n",
       "EDA_TD_T_Min             -5.783329\n",
       "EDA_TD_T_AUC          -1119.978146\n",
       "EDA_TD_T_Kurtosis        -1.716957\n",
       "EDA_TD_T_Skew            -5.620632\n",
       "EDA_TD_T_Slope_min       -0.270382\n",
       "EDA_TD_T_Slope_max       -0.000116\n",
       "EDA_TD_T_Slope_mean      -0.009898\n",
       "EDA_TD_T_Slope           -0.009191\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for Negative Values\n",
    "display(\"\\\\nMinimum values in numerical columns (checking for non-negativity):\")\n",
    "numeric_cols_check = df.select_dtypes(include=np.number).columns\n",
    "min_values = df[numeric_cols_check].min()\n",
    "display(min_values[min_values < 0]) # Show only columns with negative minimum values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03b385b",
   "metadata": {},
   "source": [
    "### Step 3: Define Column Types & Select Features\n",
    "\n",
    "**Explanation:**\n",
    "Based on the inspection and the case description (`case2_description.pdf`), we need to separate the columns into three groups:\n",
    "1.  **Metadata/Identifiers:** Columns identifying the trial, participant, phase, etc. (e.g., 'Round', 'Phase', 'Individual', 'Puzzler', 'Cohort'). These are useful for context and interpretation later but are not typically included directly in the unsupervised decomposition.\n",
    "2.  **Response Variables:** Self-reported scores (e.g., 'Frustrated', 'alert', 'nervous'). These are target variables for *supervised* analysis (like the third option in `case2_description.pdf`) but should be excluded from the *unsupervised* analysis of physiological features.\n",
    "3.  **Numerical Features:** The remaining numerical columns derived from HR, EDA, and TEMP signals. These are the features we will use for the subspace analysis, as per the instruction to use only the features from `HR_data.csv`.\n",
    "\n",
    "We'll also drop the `Unnamed: 0` column identified during inspection as it's likely just a row index from saving the CSV. We create separate DataFrames for the features (`df_features`) and metadata (`df_metadata`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdf391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 'Unnamed: 0' column.\n",
      "\n",
      "Identified 5 metadata columns.\n",
      "Identified 11 response columns.\n",
      "Identified 51 numerical feature columns for processing.\n",
      "------------------------------\n",
      "Created df_metadata with shape: (312, 5)\n",
      "Created df_features with shape: (312, 51)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- 1. Drop Unnecessary Index Column ---\n",
    "# This logic handles potential re-runs of the cell gracefully.\n",
    "if 'df_processed' not in locals():\n",
    "     if 'Unnamed: 0' in df.columns:\n",
    "         df_processed = df.drop(columns=['Unnamed: 0']).copy()\n",
    "         print(\"Dropped 'Unnamed: 0' column.\")\n",
    "     else:\n",
    "         df_processed = df.copy()\n",
    "         print(\"'Unnamed: 0' column not found, proceeding.\")\n",
    "else:\n",
    "    # If df_processed exists, check if column still needs dropping\n",
    "    if 'Unnamed: 0' in df_processed.columns:\n",
    "         df_processed = df_processed.drop(columns=['Unnamed: 0'])\n",
    "         print(\"Dropped 'Unnamed: 0' column.\")\n",
    "    # else:\n",
    "         # print(\"'Unnamed: 0' column already dropped from df_processed.\") # Optional\n",
    "\n",
    "# --- 2. Define Column Types ---\n",
    "# List known metadata/identifier/categorical columns\n",
    "metadata_cols = ['Round', 'Phase', 'Individual', 'Puzzler', 'Cohort']\n",
    "\n",
    "# List known response variable columns\n",
    "response_cols = ['Frustrated', 'upset', 'hostile', 'alert', 'ashamed',\n",
    "                 'inspired', 'nervous', 'attentive', 'afraid', 'active',\n",
    "                 'determined']\n",
    "\n",
    "# Identify potential feature columns (those not in metadata or response lists)\n",
    "potential_feature_cols = [col for col in df_processed.columns\n",
    "                          if col not in metadata_cols and col not in response_cols]\n",
    "\n",
    "# Select only numeric feature columns from the potential list\n",
    "numeric_feature_cols = df_processed[potential_feature_cols].select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "print(f\"\\nIdentified {len(metadata_cols)} metadata columns.\")\n",
    "print(f\"Identified {len(response_cols)} response columns.\")\n",
    "print(f\"Identified {len(numeric_feature_cols)} numerical feature columns for processing.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- Create Separate DataFrames ---\n",
    "# Keep metadata for potential later use (e.g., plotting)\n",
    "existing_metadata_cols = [col for col in metadata_cols if col in df_processed.columns]\n",
    "df_metadata = df_processed[existing_metadata_cols].copy()\n",
    "print(f\"Created df_metadata with shape: {df_metadata.shape}\")\n",
    "\n",
    "# Create DataFrame with only the numerical features selected\n",
    "df_features = df_processed[numeric_feature_cols].copy()\n",
    "print(f\"Created df_features with shape: {df_features.shape}\")\n",
    "print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3befafe2",
   "metadata": {},
   "source": [
    "lets inspect our new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7b59e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR_TD_Mean</th>\n",
       "      <th>HR_TD_Median</th>\n",
       "      <th>HR_TD_std</th>\n",
       "      <th>HR_TD_Min</th>\n",
       "      <th>HR_TD_Max</th>\n",
       "      <th>HR_TD_AUC</th>\n",
       "      <th>HR_TD_Kurtosis</th>\n",
       "      <th>HR_TD_Skew</th>\n",
       "      <th>HR_TD_Slope_min</th>\n",
       "      <th>HR_TD_Slope_max</th>\n",
       "      <th>...</th>\n",
       "      <th>EDA_TD_T_AUC</th>\n",
       "      <th>EDA_TD_T_Kurtosis</th>\n",
       "      <th>EDA_TD_T_Skew</th>\n",
       "      <th>EDA_TD_T_Slope_min</th>\n",
       "      <th>EDA_TD_T_Slope_max</th>\n",
       "      <th>EDA_TD_T_Slope_mean</th>\n",
       "      <th>EDA_TD_T_Slope</th>\n",
       "      <th>EDA_TD_P_Peaks</th>\n",
       "      <th>EDA_TD_P_RT</th>\n",
       "      <th>EDA_TD_P_ReT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.663878</td>\n",
       "      <td>76.70</td>\n",
       "      <td>7.480043</td>\n",
       "      <td>67.25</td>\n",
       "      <td>92.48</td>\n",
       "      <td>23048.450</td>\n",
       "      <td>-1.091448</td>\n",
       "      <td>0.369955</td>\n",
       "      <td>-0.7300</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>...</td>\n",
       "      <td>213.374114</td>\n",
       "      <td>1.345997</td>\n",
       "      <td>-1.379434</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.036040e-05</td>\n",
       "      <td>11</td>\n",
       "      <td>2.522727</td>\n",
       "      <td>2.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.540732</td>\n",
       "      <td>76.61</td>\n",
       "      <td>2.584756</td>\n",
       "      <td>69.82</td>\n",
       "      <td>82.33</td>\n",
       "      <td>23959.920</td>\n",
       "      <td>-0.245338</td>\n",
       "      <td>0.338732</td>\n",
       "      <td>-0.3600</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>...</td>\n",
       "      <td>213.235380</td>\n",
       "      <td>0.887010</td>\n",
       "      <td>0.854067</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>7.714503e-06</td>\n",
       "      <td>15</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>2.192308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.173563</td>\n",
       "      <td>77.92</td>\n",
       "      <td>2.681255</td>\n",
       "      <td>72.22</td>\n",
       "      <td>82.80</td>\n",
       "      <td>20324.605</td>\n",
       "      <td>-0.615922</td>\n",
       "      <td>-0.233047</td>\n",
       "      <td>-0.6300</td>\n",
       "      <td>0.3575</td>\n",
       "      <td>...</td>\n",
       "      <td>173.465157</td>\n",
       "      <td>0.205817</td>\n",
       "      <td>0.480581</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.799914e-06</td>\n",
       "      <td>10</td>\n",
       "      <td>1.972222</td>\n",
       "      <td>2.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83.073688</td>\n",
       "      <td>83.88</td>\n",
       "      <td>7.363598</td>\n",
       "      <td>69.42</td>\n",
       "      <td>96.12</td>\n",
       "      <td>24924.300</td>\n",
       "      <td>-0.866610</td>\n",
       "      <td>-0.046021</td>\n",
       "      <td>-0.4650</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>...</td>\n",
       "      <td>191.943390</td>\n",
       "      <td>2.488339</td>\n",
       "      <td>1.246665</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-1.355151e-07</td>\n",
       "      <td>12</td>\n",
       "      <td>1.886364</td>\n",
       "      <td>1.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72.281250</td>\n",
       "      <td>72.91</td>\n",
       "      <td>3.193762</td>\n",
       "      <td>64.95</td>\n",
       "      <td>79.98</td>\n",
       "      <td>23052.100</td>\n",
       "      <td>0.200401</td>\n",
       "      <td>-0.560948</td>\n",
       "      <td>-0.3725</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>...</td>\n",
       "      <td>192.341180</td>\n",
       "      <td>1.196508</td>\n",
       "      <td>1.592099</td>\n",
       "      <td>-0.000420</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.267198e-05</td>\n",
       "      <td>20</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>1.926471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HR_TD_Mean  HR_TD_Median  HR_TD_std  HR_TD_Min  HR_TD_Max  HR_TD_AUC  \\\n",
       "0   78.663878         76.70   7.480043      67.25      92.48  23048.450   \n",
       "1   76.540732         76.61   2.584756      69.82      82.33  23959.920   \n",
       "2   78.173563         77.92   2.681255      72.22      82.80  20324.605   \n",
       "3   83.073688         83.88   7.363598      69.42      96.12  24924.300   \n",
       "4   72.281250         72.91   3.193762      64.95      79.98  23052.100   \n",
       "\n",
       "   HR_TD_Kurtosis  HR_TD_Skew  HR_TD_Slope_min  HR_TD_Slope_max  ...  \\\n",
       "0       -1.091448    0.369955          -0.7300           0.9775  ...   \n",
       "1       -0.245338    0.338732          -0.3600           0.1900  ...   \n",
       "2       -0.615922   -0.233047          -0.6300           0.3575  ...   \n",
       "3       -0.866610   -0.046021          -0.4650           0.6500  ...   \n",
       "4        0.200401   -0.560948          -0.3725           0.3375  ...   \n",
       "\n",
       "   EDA_TD_T_AUC  EDA_TD_T_Kurtosis  EDA_TD_T_Skew  EDA_TD_T_Slope_min  \\\n",
       "0    213.374114           1.345997      -1.379434           -0.000144   \n",
       "1    213.235380           0.887010       0.854067           -0.000146   \n",
       "2    173.465157           0.205817       0.480581           -0.000112   \n",
       "3    191.943390           2.488339       1.246665           -0.000455   \n",
       "4    192.341180           1.196508       1.592099           -0.000420   \n",
       "\n",
       "   EDA_TD_T_Slope_max  EDA_TD_T_Slope_mean  EDA_TD_T_Slope  EDA_TD_P_Peaks  \\\n",
       "0            0.000138             0.000010    1.036040e-05              11   \n",
       "1            0.000165             0.000009    7.714503e-06              15   \n",
       "2            0.000132             0.000002    1.799914e-06              10   \n",
       "3            0.000481            -0.000001   -1.355151e-07              12   \n",
       "4            0.000334             0.000014    1.267198e-05              20   \n",
       "\n",
       "   EDA_TD_P_RT  EDA_TD_P_ReT  \n",
       "0     2.522727      2.075000  \n",
       "1     2.214286      2.192308  \n",
       "2     1.972222      2.111111  \n",
       "3     1.886364      1.805556  \n",
       "4     1.812500      1.926471  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f24b538",
   "metadata": {},
   "source": [
    "### Step 4: Handle Missing Values in Features\n",
    "\n",
    "**Explanation:**\n",
    "Our inspection revealed a few missing values in the `EDA_TD_P_RT` and `EDA_TD_P_ReT` columns, which we identified as numerical features for our analysis. Most machine learning algorithms, including decomposition methods, cannot handle missing data directly. We need to fill these gaps. A robust strategy for numerical data is **median imputation**, where missing values in a column are replaced by the median value of that column. Median is often preferred over mean as it's less sensitive to outliers. We will apply this only to the selected `df_features` DataFrame (assuming it was successfully created in Step 3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0c3ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 missing value(s) in feature columns. Imputing with median...\n",
      "Missing value imputation complete for features.\n",
      "Remaining missing values in features: 0\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Check for missing values specifically in the selected feature columns ---\n",
    "missing_in_features = df_features.isnull().sum().sum()\n",
    "\n",
    "if missing_in_features > 0:\n",
    "    print(f\"Found {missing_in_features} missing value(s) in feature columns. Imputing with median...\")\n",
    "\n",
    "    # Initialize the imputer with the median strategy\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "    # Keep track of column names and index\n",
    "    feature_index = df_features.index\n",
    "    feature_columns = df_features.columns\n",
    "\n",
    "    # Fit the imputer and transform the data\n",
    "    df_features_imputed_array = imputer.fit_transform(df_features)\n",
    "\n",
    "    # Convert the result back to a DataFrame\n",
    "    # Overwrite df_features with the imputed version\n",
    "    df_features = pd.DataFrame(df_features_imputed_array, index=feature_index, columns=feature_columns)\n",
    "\n",
    "    print(\"Missing value imputation complete for features.\")\n",
    "    # Verify there are no more missing values\n",
    "    print(f\"Remaining missing values in features: {df_features.isnull().sum().sum()}\")\n",
    "else:\n",
    "    # Check if df_features was already imputed in a previous run\n",
    "    if df_features.isnull().sum().sum() == 0:\n",
    "        print(\"No missing values found in selected feature columns (potentially already imputed).\")\n",
    "    else:\n",
    "         print(f\"Missing values check error. Current missing count: {df_features.isnull().sum().sum()}\")\n",
    "\n",
    "print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94916359",
   "metadata": {},
   "source": [
    "### Step 5: Scale Numerical Features\n",
    "\n",
    "**Explanation:**\n",
    "Subspace methods like PCA, SPCA, AA, and others are often sensitive to the scale of the features. Features with larger ranges can dominate the analysis, potentially masking the contribution of features with smaller ranges. To prevent this, we scale the features. **Standardization (or Z-score normalization)** is a common and effective method. It rescales each feature to have a mean of 0 and a standard deviation of 1. We apply this to our imputed numerical features (`df_features`) which are now clean of missing values (assuming Step 4 ran correctly).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31650790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying StandardScaler (Z-score normalization) to features...\n",
      "Feature scaling complete.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Applying StandardScaler (Z-score normalization) to features...\")\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the feature data and transform it\n",
    "scaled_features_array = scaler.fit_transform(df_features)\n",
    "\n",
    "# Create the final DataFrame with scaled features, preserving index and column names\n",
    "df_features_scaled = pd.DataFrame(scaled_features_array, index=df_features.index, columns=numeric_feature_cols)\n",
    "\n",
    "print(\"Feature scaling complete.\")\n",
    "print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bb863a",
   "metadata": {},
   "source": [
    "### Step 6: Display Preprocessed Results\n",
    "\n",
    "**Explanation:**\n",
    "Finally, let's look at the result of our preprocessing. We'll display the first few rows (`head()`) and the summary statistics (`describe()`) of the `df_features_scaled` DataFrame. This confirms that the features are now scaled (mean close to 0, standard deviation close to 1) and ready for the subsequent subspace analysis (like SPCA, AA, or SOM). The metadata remains available in the `df_metadata` DataFrame for later use in interpreting the results. This assumes `df_features_scaled` was created in Step 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305e27ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the final preprocessed (scaled) features:\n",
      "   HR_TD_Mean  HR_TD_Median  HR_TD_std  HR_TD_Min  HR_TD_Max  HR_TD_AUC  \\\n",
      "0    0.010023     -0.062352   0.187214  -0.163880   0.001629  -0.312526   \n",
      "1   -0.176801     -0.069806  -0.793634   0.111690  -0.570809  -0.086288   \n",
      "2   -0.033122      0.038688  -0.774299   0.369032  -0.544302  -0.988619   \n",
      "3    0.398059      0.532294   0.163883   0.068800   0.206917   0.153083   \n",
      "4   -0.551609     -0.376240  -0.671610  -0.410499  -0.703343  -0.311621   \n",
      "\n",
      "   HR_TD_Kurtosis  HR_TD_Skew  HR_TD_Slope_min  HR_TD_Slope_max  ...  \\\n",
      "0       -0.621392   -0.007322        -0.414857         0.978121  ...   \n",
      "1       -0.114281   -0.045281         0.532375        -0.699948  ...   \n",
      "2       -0.336389   -0.740408        -0.158848        -0.343025  ...   \n",
      "3       -0.486637   -0.513035         0.263566         0.280258  ...   \n",
      "4        0.152870   -1.139046         0.500374        -0.385643  ...   \n",
      "\n",
      "   EDA_TD_T_AUC  EDA_TD_T_Kurtosis  EDA_TD_T_Skew  EDA_TD_T_Slope_min  \\\n",
      "0     -0.674626           0.276417      -1.310763            0.595726   \n",
      "1     -0.674647           0.136077       0.945391            0.595677   \n",
      "2     -0.680703          -0.072207       0.568117            0.596330   \n",
      "3     -0.677889           0.625703       1.341971            0.589771   \n",
      "4     -0.677829           0.230709       1.690908            0.590443   \n",
      "\n",
      "   EDA_TD_T_Slope_max  EDA_TD_T_Slope_mean  EDA_TD_T_Slope  EDA_TD_P_Peaks  \\\n",
      "0           -0.667286             0.135978        0.096659       -1.012991   \n",
      "1           -0.666593             0.135187        0.095006       -0.689332   \n",
      "2           -0.667436             0.130645        0.091310       -1.093906   \n",
      "3           -0.658566             0.129049        0.090101       -0.932077   \n",
      "4           -0.662295             0.138101        0.098103       -0.284758   \n",
      "\n",
      "   EDA_TD_P_RT  EDA_TD_P_ReT  \n",
      "0     1.134433      0.099784  \n",
      "1     0.467560      0.290627  \n",
      "2    -0.055798      0.158532  \n",
      "3    -0.241431     -0.338565  \n",
      "4    -0.401129     -0.141853  \n",
      "\n",
      "[5 rows x 51 columns]\n",
      "------------------------------\n",
      "Summary statistics of the scaled features:\n",
      "       HR_TD_Mean  HR_TD_Median  HR_TD_std  HR_TD_Min  HR_TD_Max  HR_TD_AUC  \\\n",
      "count     312.000       312.000    312.000    312.000    312.000    312.000   \n",
      "mean        0.000         0.000      0.000      0.000     -0.000     -0.000   \n",
      "std         1.002         1.002      1.002      1.002      1.002      1.002   \n",
      "min        -1.843        -1.932     -1.144     -2.121     -1.424     -2.347   \n",
      "25%        -0.659        -0.620     -0.678     -0.706     -0.691     -0.685   \n",
      "50%        -0.155        -0.153     -0.326     -0.130     -0.261     -0.163   \n",
      "75%         0.441         0.468      0.293      0.539      0.395      0.555   \n",
      "max         6.458         7.495      5.131      4.535      4.513      5.402   \n",
      "\n",
      "       HR_TD_Kurtosis  HR_TD_Skew  HR_TD_Slope_min  HR_TD_Slope_max  ...  \\\n",
      "count         312.000     312.000          312.000          312.000  ...   \n",
      "mean           -0.000       0.000            0.000            0.000  ...   \n",
      "std             1.002       1.002            1.002            1.002  ...   \n",
      "min            -0.953      -3.169           -7.163           -0.945  ...   \n",
      "25%            -0.557      -0.641           -0.249           -0.482  ...   \n",
      "50%            -0.241      -0.018            0.283           -0.226  ...   \n",
      "75%             0.162       0.745            0.641            0.203  ...   \n",
      "max             7.531       3.464            1.166           12.112  ...   \n",
      "\n",
      "       EDA_TD_T_AUC  EDA_TD_T_Kurtosis  EDA_TD_T_Skew  EDA_TD_T_Slope_min  \\\n",
      "count       312.000            312.000        312.000             312.000   \n",
      "mean          0.000             -0.000         -0.000              -0.000   \n",
      "std           1.002              1.002          1.002               1.002   \n",
      "min          -0.878             -0.660         -5.595              -4.580   \n",
      "25%          -0.584             -0.439         -0.413              -0.137   \n",
      "50%          -0.383             -0.297          0.181               0.470   \n",
      "75%           0.245              0.076          0.603               0.547   \n",
      "max           6.825             10.181          2.780               0.597   \n",
      "\n",
      "       EDA_TD_T_Slope_max  EDA_TD_T_Slope_mean  EDA_TD_T_Slope  \\\n",
      "count             312.000              312.000         312.000   \n",
      "mean                0.000               -0.000           0.000   \n",
      "std                 1.002                1.002           1.002   \n",
      "min                -0.674               -5.972          -5.653   \n",
      "25%                -0.600               -0.318          -0.310   \n",
      "50%                -0.456                0.057           0.041   \n",
      "75%                 0.110                0.189           0.161   \n",
      "max                 5.492                4.849           5.024   \n",
      "\n",
      "       EDA_TD_P_Peaks  EDA_TD_P_RT  EDA_TD_P_ReT  \n",
      "count         312.000      312.000       312.000  \n",
      "mean           -0.000       -0.000        -0.000  \n",
      "std             1.002        1.002         1.002  \n",
      "min            -1.822       -1.617        -1.920  \n",
      "25%            -0.770       -0.671        -0.571  \n",
      "50%            -0.204       -0.176        -0.133  \n",
      "75%             0.605        0.399         0.318  \n",
      "max             4.085        7.369         6.417  \n",
      "\n",
      "[8 rows x 51 columns]\n",
      "------------------------------\n",
      "Preprocessing finished.\n",
      "DataFrame 'df_features_scaled' contains the scaled numerical features.\n",
      "DataFrame 'df_metadata' contains the corresponding metadata.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- Display head of the scaled features ---\n",
    "print(\"First 5 rows of the final preprocessed (scaled) features:\")\n",
    "print(df_features_scaled.head())\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- Display summary statistics of the scaled features ---\n",
    "# Note: Mean should be ~0 and std dev should be ~1 for all columns\n",
    "print(\"Summary statistics of the scaled features:\")\n",
    "# Use .round(3) to make the describe output cleaner\n",
    "print(df_features_scaled.describe().round(3))\n",
    "print(\"-\" * 30)\n",
    "\n",
    "print(\"Preprocessing finished.\")\n",
    "print(\"DataFrame 'df_features_scaled' contains the scaled numerical features.\")\n",
    "print(\"DataFrame 'df_metadata' contains the corresponding metadata.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b78d6c",
   "metadata": {},
   "source": [
    "### Step 7: Save Preprocessed Data to CSV Files\n",
    "\n",
    "**Explanation:**\n",
    "After completing the preprocessing (handling missing values, scaling features, separating metadata), it's useful to save the results. \n",
    "1.  `df_features_scaled`: The DataFrame containing only the numerical physiological features, now imputed and standardized.\n",
    "2.  `df_metadata`: The DataFrame containing the corresponding metadata columns (like Individual, Round, Phase, Cohort).\n",
    "\n",
    "We save them as separate CSV files. The `index=False` argument prevents pandas from writing the DataFrame index as a column in the CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bea352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled features saved successfully to HR_features_scaled.csv\n",
      "Metadata saved successfully to HR_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define output filenames\n",
    "scaled_features_filepath = 'HR_features_scaled.csv'\n",
    "metadata_filepath = 'HR_metadata.csv'\n",
    "\n",
    "try:\n",
    "    # Check if the DataFrames exist before trying to save\n",
    "    if 'df_features_scaled' in locals() and df_features_scaled is not None:\n",
    "        # Save the scaled features\n",
    "        df_features_scaled.to_csv(scaled_features_filepath, index=False)\n",
    "        print(f\"Scaled features saved successfully to {scaled_features_filepath}\")\n",
    "    else:\n",
    "        print(f\"Error: DataFrame 'df_features_scaled' not found. Cannot save.\")\n",
    "\n",
    "    if 'df_metadata' in locals() and df_metadata is not None:\n",
    "         # Save the metadata\n",
    "        df_metadata.to_csv(metadata_filepath, index=False)\n",
    "        print(f\"Metadata saved successfully to {metadata_filepath}\")\n",
    "    else:\n",
    "         print(f\"Error: DataFrame 'df_metadata' not found. Cannot save.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while saving the files: {e}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
